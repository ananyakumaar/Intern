{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0RJUQWqUtxVKcTO55jBzE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananyakumaar/anan/blob/main/LangPDFreader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7aIUdXPjyn0",
        "outputId": "100bf29d-e35c-492f-80a7-4e3c574c26fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.5-py3-none-any.whl (974 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.7 (from langchain)\n",
            "  Downloading langchain_core-0.2.9-py3-none-any.whl (321 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.81-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.7->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.5 langchain-core-0.2.9 langchain-text-splitters-0.2.1 langsmith-0.1.81 orjson-3.10.5\n",
            "Collecting openai\n",
            "  Downloading openai-1.35.1-py3-none-any.whl (326 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.8/326.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.1\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.5)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.9)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.81)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain-community) (2.7.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain-community) (2.18.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.5 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install PyPDF2\n",
        "!pip install faiss-cpu\n",
        "!pip install -U langchain-community\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import OpenAI\n"
      ],
      "metadata": {
        "id": "g4IOGlSAkHvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# List the files uploaded to the current directory\n",
        "import os\n",
        "print(os.listdir())\n",
        "\n",
        "# upload the pdf\n",
        "pdf_path = \"GAN.pdf\"\n",
        "\n",
        "# Create a PdfReader object\n",
        "pdfreader = PdfReader(pdf_path)\n",
        "\n",
        "# Extract text from the first page\n",
        "page = pdfreader.pages[0]\n",
        "text = page.extract_text()\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsCiYGyQkJos",
        "outputId": "d9210543-ef60-48fa-e881-a0d41f81af55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'GAN.pdf', 'sample_data']\n",
            "UNITIII\n",
            "HIGHDIMENSION ALOBJE CT SANDS AMPLING\n",
            "Gener ativemodelsfortext-VariationalAutoencoders-Gener ativeAdversarialNetw orks-Forw ardsampling-Importancesampling-MCMCsampling\n",
            "GENERA TIVEMODEL SF ORTEXT\n",
            "Gener ativemodelsareaclassofmodelsintheunsupervisedmachinelearningspace.Theyhelp ustomodeltheunder lyingdistributionsresponsibleforgener atingthedatasetunderconsider ation.Ther earedifferentmethods/fr amew orkstoworkwithgener ativemodels.Thefirstsetofmethodscorr espondstomodelsthatrepresentdatawithanexplicitdensityfunction.Herewedefineaprobabilitydensityfunction,\n",
            "p\n",
            "Θ\n",
            ",explicitl yanddevelopamodelthatincr easesthemaximumlikelihoodofsamplingfromthisdistribution.\n",
            "Ther earetwofurthertypeswithinexplicitdensitymethods,\n",
            "tractableand\n",
            "approximatedensitymethods.PixelRNNsareanactiveareaofresear chfortractabledensitymethods.Whenwetrytomodelcomple xreal-w orlddatadistributions,forexample,natur alimagesorspeechsignals,definingaparametricfunctionbecomeschallenging.Thesetechniquesworkbyappr oximatingtheunder lyingprobabilitydensityfunctionsexplicitl y.VAEsworktowardsmaximizingthelikelihoodestimat esofthelowerbound,whileRBMsuseMar kovchainstomak eanestimat eofthedistribution.\n",
            "Taxonom yofGener ativeModels\n",
            "GANSfallunderimplicitdensitymodelingmethods.Theimplicitdensityfunctionsgiveupthepropertyofexplicitl ydefiningtheunder lyingdistributionbutworkbydefiningmethodstodrawsamplesfromsuchdistributions.TheGANframew orkisaclassofmethodsthatcansampledirectlyfromtheunder lyingdistributions.Thisalleviatessomeof\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "OPENAI_API_KEY = \"YOUR OPEN API KEY\""
      ],
      "metadata": {
        "id": "sWhiQGdu2xjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Concatenate\n",
        "raw_text=''\n",
        "for i,page in enumerate(pdfreader.pages):\n",
        "    content=page.extract_text()\n",
        "    if content:\n",
        "        raw_text+=content"
      ],
      "metadata": {
        "id": "WnBccIU53AjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "QR33irBx3Dvc",
        "outputId": "f13a38f6-5c63-497d-f21d-d41b6cceddd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'UNITIII\\nHIGHDIMENSION ALOBJE CT SANDS AMPLING\\nGener ativemodelsfortext-VariationalAutoencoders-Gener ativeAdversarialNetw orks-Forw ardsampling-Importancesampling-MCMCsampling\\nGENERA TIVEMODEL SF ORTEXT\\nGener ativemodelsareaclassofmodelsintheunsupervisedmachinelearningspace.Theyhelp ustomodeltheunder lyingdistributionsresponsibleforgener atingthedatasetunderconsider ation.Ther earedifferentmethods/fr amew orkstoworkwithgener ativemodels.Thefirstsetofmethodscorr espondstomodelsthatrepresentdatawithanexplicitdensityfunction.Herewedefineaprobabilitydensityfunction,\\np\\nΘ\\n,explicitl yanddevelopamodelthatincr easesthemaximumlikelihoodofsamplingfromthisdistribution.\\nTher earetwofurthertypeswithinexplicitdensitymethods,\\ntractableand\\napproximatedensitymethods.PixelRNNsareanactiveareaofresear chfortractabledensitymethods.Whenwetrytomodelcomple xreal-w orlddatadistributions,forexample,natur alimagesorspeechsignals,definingaparametricfunctionbecomeschallenging.Thesetechniquesworkbyappr oximatingtheunder lyingprobabilitydensityfunctionsexplicitl y.VAEsworktowardsmaximizingthelikelihoodestimat esofthelowerbound,whileRBMsuseMar kovchainstomak eanestimat eofthedistribution.\\nTaxonom yofGener ativeModels\\nGANSfallunderimplicitdensitymodelingmethods.Theimplicitdensityfunctionsgiveupthepropertyofexplicitl ydefiningtheunder lyingdistributionbutworkbydefiningmethodstodrawsamplesfromsuchdistributions.TheGANframew orkisaclassofmethodsthatcansampledirectlyfromtheunder lyingdistributions.Thisalleviatessomeof\\nthecomple xitiesassociat edwiththemethodswehavecoveredsofar,suchasdefiningunder lyingprobabilitydistributionfunctionsandthequalityofoutputs.\\nV ARIA TION ALA UT OENC ODER S\\nVAEinterpr etableasadirectedlatent-v ariableProbabilisticGraphicalModel.\\nAvariationalautoencoder(VAE)providesaprobabilisticmannerfordescribinganobserv ationinlatentspace.Thus,ratherthanbuildinganencoderthatoutputsasing levaluetodescribeeachlatentstateattribut e,we’llformulat eourencodertodescribeaprobabilitydistributionforeachlatentattribut e.\\nAVAEisanautoencoderwhoseencodingsdistributionisregularizedduringthetraininginordertoensur ethatitslatentspacehasgoodpropertiesallowingustogener atesomenewdata.\\nIthasman yapplicationssuchasdatacompr ession,syntheticdatacreationetc.\\nAr chit ectur e:\\nAutoencodersareatypeofneur alnetw orkthatlearnsthedataencodingsfromthedatasetinanunsupervisedway.Itbasicall ycontainstwoparts:thefirstoneisanencoderwhichissimilartotheconvolutionneur alnetw orkexceptforthelastlayer.Theaimoftheencodertolearnefficientdataencodingfromthedatasetandpassitintobottleneckarchitectur e.Theotherpartoftheautoencoderisadecoderthatuseslatentspaceinthebottlenecklayertoregener atetheimagessimilartothedataset .Theseresultsback propag atefromtheneur alnetw orkintheformofthelossfunction.\\nVariationalautoencoderisdifferentfromautoencoderinawaysuchthatitprovidesastatisticmannerfordescribingthesamplesofthedatasetinlatentspace.Ther efore,invariationalautoencoder ,theencoderoutputsaprobabilitydistributioninthebottlenecklayerinsteadofasing leoutputvalue.●Trainingdataismappedtolatentspaceusingneur alnetw ork \\n●Thelatentspacevectorismappedtoinputimageusinganotherneur alnetw ork. \\n●ComponentsofvariationalautoencoderoEncoderoDecoderoRegularizedlossfunction\\n●EncoderoIttakestrainingdataasinputandproducesalatentrepresentationZoThelatentrepresentationisstochastici.e.Theyareparamet ersofaprobabilitydistribution.oq∅\\n Paramet ersofencoder\\n●DecoderoZissampledfromtheoutputoftheencoderandgivestheinputtodecoderoDecoderoutputssimilartoxi.etheregener ateddata \\n●VAELossfunction\\nTerm1representregularizerandterm2isdatareconstructionloss\\nRegularizeristheKLdivergenceoftheoutputbytheencodernetw orkandpriormodelforthedistributionofZ.bothmodeledusinggaussiondistribution.KLsaysabouthowsimilarthedistributionsare.Iftheyareexactlysamethenitwillbe0.\\nTher eisbothacontinuousformofKLdivergence\\nAndadiscr eteformofKLDivergence:\\nGENERA TIVEAD VER S ARIALNETW ORKS\\nGANsareatypeofneur alnetw orkusedforunsupervisedmachinelearning.Theyarecomprisedoftwoadversarialmodules: g ener at or and c ost netw orks.Thesemodulescompet ewitheachothersuchthatthe c ost netw orktriestofilterfakeexampleswhilethe g ener at or triestotrickthisfilterbycreatingrealistic\\nexamples \\n�\\n^x^.Throughthiscompetition,themodellearnsagener atorthatcreatesrealisticdata.Theycanbeusedintask ssuchasfutur epredictionsorforgener atingimagesafterbeingtrainedonaparticulardataset .\\n●Gener ati v e:Tolearnagener ativemodel,whichdescribeshowdataisgener atedintermsofaprobabilisticmodel. \\n●A d v ersarial:Thetrainingofamodelisdoneinanadversarialsetting.\\n●Netw or ks:Usedeepneur alnetw orksasartificialintelligence(AI)algorithmsfortrainingpurposes.\\nAgener ativeadversarialnetw ork(GAN)hastwoparts:\\n●Thegener at orlearnstogener ateplausibledata.Thegener atedinstancesbecomenegativetrainingexamplesforthediscriminat or. \\n●Thediscriminat orlearnstodistinguishthegener ator\\'sfakedatafromrealdata.Thediscriminat orpenalizesthegener atorforproducingimplausibleresults.\\nInGANs,ther eisaGener atorandaDiscriminat or.TheGener atorgener atesfakesamplesofdata(beitanimage,audio,etc.)andtriestofooltheDiscriminat or.TheDiscriminat or,ontheotherhand,triestodistinguishbetw eentherealandfakesamples.TheGener atorandtheDiscriminat orarebothNeur alNetw orksandtheybothrunincompetitionwitheachotherinthetrainingphase.Thestepsarerepeat edseveraltimesandinthis,theGener atorandDiscriminat orgetbett erandbett erintheirrespecti vejobsaftereachrepetition.Theworkcanbevisualizedbythediagr amgivenbelo w:\\nw h e r e ,\\n●G=G e n e r a t o r \\n●D=D i s c r i m i n a t o r \\n●P d a t a ( x )=d i s t r i b u t i o no fr e a ld a t a \\n●P ( z )=d i s t r i b u t i o no fg e n e r a t o r \\n●x=s a m p l ef r o mP d a t a ( x )\\n●z=s a m p l ef r o mP ( z ) \\n●D ( x )=D i s c r i m i n a t o rn e t w o r k \\n●G ( z )=G e n e r a t o rn e t w o r k\\nTheDiscriminat or\\nThediscriminat orinaGANissimpl yaclassifier .Ittriestodistinguishrealdatafromthedatacreatedbythegener ator.Itcoulduseanynetw orkarchitectur eappr opriat etothetypeofdatait\\'sclassifying.\\nDiscriminatorTrainingData\\nThediscriminat or\\'strainingdatacomesfromtwosour ces:\\n●R ealdatainstances,suchasrealpictur esofpeople.Thediscriminat orusestheseinstancesaspositi veexamplesduringtraining. \\n●F ak edatainstancescreatedbythegener ator.Thediscriminat orusestheseinstancesasnegativeexamplesduringtraining.\\nInFigur e1,thetwo\"Sample \"boxesrepresentthesetwodatasour cesfeedingintothediscriminat or.Duringdiscriminat ortrainingthegener atordoesnottrain.Itsweightsremainconstantwhileitproducesexamplesforthediscriminat ortotrainon.\\nTrainingtheDiscriminator\\nThediscriminat orconnectstotwolossfunctions.Duringdiscriminat ortraining,thediscriminat orignor esthegener atorlossandjustusesthediscriminat orloss.Weusethegener atorlossduringgener atortraining,asdescribedinthenextsection.\\nDuringdiscriminat ortraining:\\n1.Thediscriminat orclassifiesbothrealdataandfakedatafromthegener ator.2.Thediscriminat orlosspenalizesthediscriminat orformisclassifyingarealinstanceasfakeorafakeinstanceasreal.3.Thediscriminat orupdat esitsweightsthroughback propag ationfromthediscriminat orlossthroughthediscriminat ornetw ork.\\nTheGener at or\\nThegener atorpartofaGANlearnstocreatefakedatabyincorpor atingfeedbackfromthediscriminat or.Itlearnstomak ethediscriminat orclassifyitsoutputasreal.\\nGener atortrainingrequir estighterintegrationbetw eenthegener atorandthediscriminat orthandiscriminat ortrainingrequir es.TheportionoftheGANthattrainsthegener atorincludes:\\n●randominput \\n●gener atornetw ork,whichtransf ormstherandominputintoadatainstance \\n●discriminat ornetw ork,whichclassifiesthegener ateddata \\n●discriminat oroutput \\n●gener atorloss,whichpenalizesthegener atorforfailingtofoolthediscriminat or\\nTrainthegener atorwiththefollowingprocedur e:\\n1.Samplerandomnoise.2.Producegener atoroutputfromsampledrandomnoise.3.Getdiscriminat or\"Real\"or\"Fake\"classificationforgener atoroutput .4.Calculat elossfromdiscriminat orclassification.5.Back propag atethroughboththediscriminat orandgener atortoobtaingradients.\\n6.Usegradientstochangeonlythegener atorweights.\\nThisisoneiterationofgener atortraining.\\nLossFunctions\\nGANstrytoreplicat eaprobabilitydistribution.Theyshouldther eforeuselossfunctionsthatreflectthedistancebetw eenthedistributionofthedatagener atedbytheGANandthedistributionoftherealdata.\\nHowdoyoucaptur ethedifferencebetw eentwodistributionsinGANlossfunctions?Thisquestionisanareaofactiveresear ch,andman yappr oacheshavebeenproposed.We\\'lladdr esstwocommonGANlossfunctionshere,bothofwhichareimplement edinTF-GAN:\\n●minimaxloss \\n●W asserst einloss\\nTF-GANimplementsman yotherlossfunctionsaswell.\\nOneLossFunctionorTwo?\\nAGANcanhavetwolossfunctions:oneforgener atortrainingandonefordiscriminat ortraining.Howcantwolossfunctionsworktogethertoreflectadistancemeasur ebetw eenprobabilitydistributions?\\nInthelossschemeswe\\'lllookathere,thegener atoranddiscriminat orlossesderi vefromasing lemeasur eofdistancebetw eenprobabilitydistributions.Inbothoftheseschemes,however,thegener atorcanonlyaffectoneterminthedistancemeasur e:thetermthatreflectsthedistributionofthefakedata.Soduringgener atortrainingwedroptheotherterm,whichreflectsthedistributionoftherealdata.\\nThegener atoranddiscriminat orlosseslookdifferentintheend,eventhoug htheyderi vefromasing leformula.\\nMinimaxLoss\\nInthepaperthatintroducedGANs,thegener atortriestominimizethefollowingfunctionwhilethediscriminat ortriestomaximizeit:\\nInthisfunction:\\n●D(x)isthediscriminat or\\'sestimat eoftheprobabilitythatrealdatainstancexisreal.\\n●Existheexpect edvalueoverallrealdatainstances. \\n●G(z)isthegener ator\\'soutputwhengivennoisez. \\n●D(G(z))isthediscriminat or\\'sestimat eoftheprobabilitythatafakeinstanceisreal. \\n●Ezistheexpect edvalueoverallrandominputstothegener ator(ineffect,theexpect edvalueoverallgener atedfakeinstancesG(z)). \\n●Theformuladeri vesfromthecross-entr opybetw eentherealandgener ateddistributions.\\nModifiedMinimaxLoss\\nTheoriginalGANpapernotesthattheaboveminimaxlossfunctioncancausetheGANtogetstuckintheearlystagesofGANtrainingwhenthediscriminat or\\'sjobisveryeasy.Thepaperther eforesuggestsmodifyingthegener atorlosssothatthegener atortriestomaximizelogD(G(z)).\\nWasserst einLoss\\nBydefault ,TF-GANusesWasserst einloss.\\nThislossfunctiondependsonamodificationoftheGANscheme(called\"Wasserst einGAN\"or\"WGAN\")inwhichthediscriminat ordoesnotactuall yclassifyinstances.Foreachinstanceitoutputsanumber .Thisnumberdoesnothavetobelessthanoneorgreaterthan0,sowecan\\'tuse0.5asathresholdtodecidewhetheraninstanceisrealorfake.Discriminat ortrainingjusttriestomak etheoutputbiggerforrealinstancesthanforfakeinstances.\\nBecauseitcan\\'treallydiscriminat ebetw eenrealandfake,theWGANdiscriminat orisactuall ycalleda\"critic\"insteadofa\"discriminat or\".Thisdistinctionhastheor eticalimportance,butforpracticalpurposeswecantreatitasanackno wledgementthattheinputstothelossfunctionsdon\\'thavetobeprobabilities.\\nThelossfunctionsthemsel vesaredecepti velysimple:\\nCriticLoss:D(x)-D(G(z))\\nThediscriminat ortriestomaximizethisfunction.Inotherwords,ittriestomaximizethedifferencebetw eenitsoutputonrealinstancesanditsoutputonfakeinstances.\\nGener at orLoss:D(G(z))\\nThegener atortriestomaximizethisfunction.Inotherwords,Ittriestomaximizethediscriminat or\\'soutputforitsfakeinstances.\\nInthesefunctions:\\n●D(x)isthecritic\\'soutputforarealinstance. \\n●G(z)isthegener ator\\'soutputwhengivennoisez. \\n●D(G(z))isthecritic\\'soutputforafakeinstance.●TheoutputofcriticDdoesnothavetobebetw een1and0. \\n●Theformulasderi vefromtheearthmoverdistancebetw eentherealandgener ateddistributions.\\nInTF-GAN,seewasserst ein_gener ator_lossandwasserst ein_discriminat or_lossforimplementations.\\nF o r w a r d\\ns a m p l i n g\\nThesimplestappr oachtothegener ationofparticlesisforw ardsampling.Inthis,randomsamples\\nξ\\n[1],...,\\nξ\\n[\\nM]aregener atedfromthedistributionP(X).StepsinForw ardsampling\\n●gener ateparticlesfromPB(X)bysamplingfromaBayesiannetw ork\\n●anal yzethenumberofparticlesneededinordertogetagoodappr oximationoftheexpectationofsometargetfunctionf.Difficultiesingener atingsamplesfromthepost eriorPB(X|e)shouldalsobetakencarewhilesampling.\\nSamplingfr omaBay e sianNet w or k\\nSamplethenodesinsomeorderconsist entwiththepartialorderoftheBN,sothatbythetimewesampleanodewehavevaluesforallofitsparents.ThensamplefromthedistributiondefinedbytheCPDandbythechosenvaluesforthenode’sparents.Thealgorithmrequir estheabilitytosamplefromthedistributionsunder lyingourCPD .Suchsamplingisstraightforw ardinthediscr etecase,butsubtlerwhendealingwithcontinuousmeasur es\\nUsingbasicconvergencebounds,fromasetofparticlesboundD=\\n{\\nξ\\n[1],...,\\nξ\\n[\\nM]}gener atedviathissamplingprocess,theexpectationofanyfunctioncanbeestimat edas\\nA nalysisofErr or\\nThequalityoftheestimat eobtaineddependsheavilyonthenumberofparticlesgener ated.Thequestionisthenumberofparticlesrequir edtoobtaincertainperf ormanceguar antees.Thequalityofourestimat eforaparticulareventY=y.WedefineanewrandomvariableovertheprobabilityspaceofP,usingtheindicat orfunctionI{Y=y}.ThisisaBernoullirandomvariable,andhenceourMparticlesinDdefineMindependentBernoullitrials,eachwithsuccessprobabilityP(y).Thisestimat eisclosetothetruthwithhighprobability:\\nThisanal ysisprovidesuswithanestimat eofhowman ysamplesarerequir edtoachie veanestimat ewhoseerrorisboundedby,withprobabilityatleast1\\n−\\nδ\\n.Setting\\nanddoingsimplealgebr aicmanipulations,wegetthattherequir edsamplesizetogetanestimat orwith\\n(\\nε\\n,\\nδ\\n)reliabilityis:\\nThenumberofrequir edsamplesgrowsinversel ywiththeprobabilityP(y).\\nM a r k o v\\nC h a i n\\nM o n t e\\nC a r l o\\nS a m p l i n g\\nMar kovChainMont eCarlosamplingprovidesaclassofalgorithmsforsystematicrandomsamplingfromhigh-dimensionalprobabilitydistributionswherethenextsampleisdependentuponthecurr entsample.GibbsSamplingandMetr opolis-Hastingsalgorithmarethetwomostcommonappr oachestoMar kovChainMont eCarlosampling.Mont eCarloisatechniqueforrandoml ysamplingaprobabilitydistributionandappr oximatingadesir edquantity .Mont eCarlomethodstypicall yassumethatwecanefficientl ydrawsamplesfromthetargetdistribution.Fromthesamplesthataredrawn,wecanthenestimat ethesumorintegralquantityasthemeanorvarianceofthedrawnsamples.Mar kovchainisasystematicmethodforgener atingasequenceofrandomvariableswherethecurr entvalueisprobabilisticall ydependentonthevalueofthepriorvariable.Specificall y,selectingthenextvariableisonlydependentuponthelastvariableinthechain.\\nCombiningthesetwomethods,Mar kovChainandMont eCarlo,allowsrandomsamplingofhigh-dimensionalprobabilitydistributionsthathonorstheprobabilisticdependencebetw eensamplesbyconstructingaMar kovChainthatcomprisestheMont eCarlosample.\\nMCMCisacomput er–dri vensamplingmethod.Itallowsonetochar acterizeadistributionwithoutknowingallofthedistribution ’smathematicalpropertiesbyrandoml ysamplingvaluesoutofthedistribution.AparticularstrengthofMCMCisthatitcanbeusedtodrawsamplesfromdistributionsevenwhenallthatisknownaboutthedistributionishowtocalculat ethedensityfordifferentsamples.ThenameMCMCcombinestwoproperties:Mont e–Car loandMar kovchain.Mont e–Car loisthepracticeofestimatingthepropertiesofadistributionbyexaminingrandomsamplesfromthedistribution.Forexample,insteadoffindingthemeanofanormaldistributionbydirectlycalculatingitfromthedistribution ’sequations,aMont e–Car loappr oachwouldbetodrawalargenumberofrandomsamplesfromanormaldistribution,andcalculat ethesamplemeanofthose.ThebenefitoftheMont e–Car loappr oachisclear:calculatingthemeanofalargesampleofnumberscanbemucheasierthancalculatingthemeandirectlyfromthenormaldistribution ’sequations.Thisbenefitismostpronouncedwhenrandomsamplesareeasytodraw,andwhenthedistribution ’sequationsarehardtoworkwithinotherways.TheMar kovchainpropertyofMCMCistheideathattherandomsamplesaregener atedbyaspecialsequentialprocess.Eachrandomsampleisusedasasteppingstonetogener atethenextrandomsample(hencethechain).Aspecialpropertyofthechainisthat ,whileeachnewsampledependsontheonebeforeit,newsamplesdonotdependonanysamplesbeforethepreviousone(thisisthe“Mar kov”property).MCMCisparticular lyusefulinBayesianinferencebecauseofthefocusonpost eriordistributionswhichareoftendifficulttoworkwithviaanal yticexamination.Inthesecases,MCMCallowstheusertoappr oximat easpectsofpost eriordistributionsthatcannotbedirectlycalculat ed(e.g.,randomsamplesfromthepost erior ,post eriormeans,etc.).Bayesianinferenceusestheinformationprovidedbyobserv eddataabouta(setof)paramet er(s),formall ythelikelihood,toupdat eapriorstateofbelief sabouta(setof)paramet er(s)tobecomeapost eriorstateofbelief sabouta(setof)paramet er(s).Formall y,Bayes’ruleisdefinedas\\np(\\nμ\\n|\\nD)\\n∝\\np(D|\\nμ\\n)\\n⋅\\np(\\nμ\\n)\\nwhere\\nμindicat esa(setof)paramet er(s)ofinterestandDindicat esthedata,\\np(\\nμ\\n|\\nD)indicat esthepost eriorortheprobabilityof\\nμgiventhedata,\\np(D|\\nμ\\n)indicat esthelikelihoodortheprobabilityofthedatagiven\\nμ\\n,and\\np(\\nμ\\n)indicat esthepriororthea–prioriprobabilityof\\nμ\\n.Thesymbol\\n∝means“isproportionalto”.Theimportantpointforthisexpositionisthatthewaythedataareusedtoupdat ethepriorbeliefisbyexaminingthelikelihoodofthedatagivenacertain(setof)value(s)oftheparamet er(s)ofinterest.Ideall y,onewouldliketoassessthislikelihoodforeverysing lecombinationofparamet ervalues.Whenananal yticalexpressionforthislikelihoodisavailable,itcanbecombinedwiththepriortoderi vethepost erioranal yticall y.Oftentimesinpractice,onedoesnothaveaccesstosuchananal yticalexpression.InBayesianinference,thisproblemismostoftensolvedviaMCMC:drawingasequenceofsamplesfromthepost erior ,andexaminingtheirmean,range,andsoon.Bayesianinferencehasbenefit edgreatlyfromthepowerofMCMC.Eveninjustinthedomainofpsychology ,MCMChasbeenappliedinavastrangeofresear chparadigms,includingBayesianmodelcomparison,memoryretention,signaldetectiontheory ,extrasensoryperception,multinomialprocessingtrees,risktaking,heuristicdecisionmakingandprimat edecisionmaking.\\nTheGibbsS amplingalgorithmisanappr oachtoconstructingaMar kovchainwheretheprobabilityofthenextsampleiscalculat edastheconditionalprobabilitygiventhepriorsample.Samplesareconstruct edbychangingonerandomvariableatatime,meaningthatsubsequentsamplesareverycloseinthesear chspace,e.g.local.Assuch,ther eissomeriskofthechaingettingstuck.\\nImportanca `amplig \\ncxpoclalion \\nsome dzbuoo \\nExDaclalon can \\nsamples 2Li3. \\neslmaling \\nSamples can be \\ndatbuten SY \\nepanive to \\nP ppaoach \\nancton \\nbe ematd by geeing \\nz \\nM m) P and \\ngonaaad using propos \\nto geneata sampa om P. \\ncan be poaleier dtebon dor \\nbayenias naloot or psior dulibaten \\nMasboy hatoo compatinaveny onP. Jecess \\nadjut te Value baJ \\naverag o nclion ando Vaiabla not posi be to P(x) \\ncoeighl alalEne toP \\nnosmalirg cosat z \\nBut t \\nkted assued ta P knoon Dn unnosmalied iroportanee samplia \\nuncig ) Cases \\nNamad Drnporana Sompliy \\ninpelanca samplig \\nimporanca sanpling emalor or \\nveLage ten the elimalo is caed as unnermal\\'xod \\nPe \\nSanpli J fo) plx) dlay calalaig \\nUsing \\nEp(f) -\\nEpe \\nEpl) \\nPe Lhlx E \\nUhnernalegnca Sa PCx)-2 PCx) \\nestimata Can be onen \\nCfx3 \\n2 P(2) \\naCx) \\nPCx) f) \\nG() P (2) \\nE&c L(x)] \\nf(Im)to(lm) -\\nît \\nprDvi \\ndes andon \\nsarmpling \\ntom \\nhgh detibon \\nBhugh - demennona MARKOV \\nCHAIN \\nMoNTE \\nCARLO-OAMPLING sampng \\neslmalar eslemator \\ncalled normalizad imporance '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter=CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=800,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        ")\n",
        "texts=text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zql0Jn3Z3F-K",
        "outputId": "5bde04ec-3a2d-47d9-f560-a9d78f575456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 822, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1944, which is longer than the specified 800\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 939, which is longer than the specified 800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uazYgSKA3K7b",
        "outputId": "eb846cc6-62dc-4fca-bea3-a9ade6d4271d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfLK8UKJ3Qo-",
        "outputId": "c98c892f-7cd7-49c2-851a-81d50a8ffe56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documentsearch=FAISS.from_texts(texts,embeddings)"
      ],
      "metadata": {
        "id": "cM8Egh9R3UJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import openai"
      ],
      "metadata": {
        "id": "INJmrzZ63ZBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = load_qa_chain(OpenAI(api_key=OPENAI_API_KEY), chain_type=\"stuff\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGWQb9Di3epo",
        "outputId": "acde1f53-3151-4d58-e1a4-73596a7998c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_query(query):\n",
        "    docs = documentsearch.similarity_search(query)\n",
        "    answer = qa_chain.run(input_documents=docs, question=query)\n",
        "    return answer"
      ],
      "metadata": {
        "id": "DkcIQXV-3k7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "    \"What do you mean by variational encoders?\"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    answer = answer_query(query)\n",
        "    print(f\"Query: {query}\\nAnswer: {answer}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpQzpyNw3p4i",
        "outputId": "616eccd5-4380-4f68-842e-e0be106e95fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What do you mean by variational encoders?\n",
            "Answer:  Variational encoders are a type of neural network that takes training data as input and produces a latent representation in the form of a probability distribution. This is different from traditional autoencoders, which typically output a single value in the bottleneck layer. Variational encoders are useful for tasks such as data compression and generating synthetic data. They are also regularized during training to ensure a good distribution of the latent space.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}